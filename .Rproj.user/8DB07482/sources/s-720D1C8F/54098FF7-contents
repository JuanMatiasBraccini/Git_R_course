# MS698 - Statistical and Graphical Analysis in R                     Fall, 2010 

# Instructor:	Janos (John) M. Hoenig 
# Contact:	hoenig@vims.edu  
#           office: x7125; home: 757 564 9766; cell: 804 815 2912


# Z-test and t-test
#
###############################################################################
# preliminary "black magic": I'll come up with sample results for 2 treatments.
#                            Don't worry about how I get them.
set.seed(23186)
xdata <- rnorm(6)
ydata <- rnorm(6)
xdata.orig <- xdata
ydata.orig <- ydata
###############################################################################
#
# OK, now let's look at the data

xdata
ydata
fulldata <- c(xdata,ydata)
datarange <- c(min(fulldata)-.6,max(fulldata + .6))
par(mfrow=c(2,1))
hist(xdata,xlim=datarange,breaks=5)
hist(ydata,xlim=datarange,breaks=5)

# It looks like the mean of the population from which the xdata were drawn is
# different from the mean of the population from which the ydata were drawn
meanofx <- mean(xdata)
meanofy <- mean(ydata)
difference_in_means <- mean(xdata)-mean(ydata)

meanofx
meanofy
difference_in_means

# QUESTION: do we have enough evidence to conclude that the two population 
# means are different? Or could the observed difference in the sample means
# be due to chance alone?

################################################################################

round(sd(xdata),digits=1)
round(sd(ydata),digits=1)

# the standard deviations look similar. Let's assume they're the same and equal
# to 1.6

# now, let us repeatedly generate samples from two populations with the same 
# mean and standard deviation (say, mean = 0, sd = 1.6. Each time, we'll
# make histograms and record the difference in means.

xdata <- rnorm(6,mean=0,sd=1.6)   # generate 6 random numbers from a normal
                                  # distribution with mean 0 and std. dev. = 1.6
ydata <- rnorm(6,mean=0,sd=1.6)

xdata
ydata
fulldata <- c(xdata,ydata)
datarange <- c(min(fulldata)-.6,max(fulldata + .6))

par(mfrow=c(2,1))
hist(xdata,xlim=datarange,breaks=5)
hist(ydata,xlim=datarange,breaks=5)

mean(xdata)
mean(ydata)
mean(xdata)-mean(ydata)

##############################################################################
# temporary storage of results
# diffs <- c(-.66,-.08,-.64,-1.34,2.38,-.79,-.12,1.12,-.47)
##############################################################################


# let's simplify the calculation of a simulated difference in sample means
mean(rnorm(6,0,1.6))-mean(rnorm(6,0,1.6))
# now we can run the line above repeatedly and get an idea of what random
# differences in sample means looks like

# in fact, we can automate this process and randomly generate 20 pairs of sample
# results

sample.diffs <- NULL
sample.diffs
for(i in 1:20) sample.diffs <- c(sample.diffs,mean(rnorm(6,0,1.6))-mean(rnorm(6,0,1.6)))
sample.diffs

# so, when the two samples come from the same population, how variable are the
# results?
# let's combine our 20 simulated results with the ones we did previously
sample.diffs <- c(sample.diffs,c(-.66,-.08,-.64,-1.34,2.38,-.79,-.12,1.12,-.47))
hist(sample.diffs)
arrows(1.06,6,1.06,4,col=2,lwd=2)
range(sample.diffs)
mean(sample.diffs)
                    # we see that a difference of 1.05 is not that unusual
                    # given the small small sample sizes (6 observations per
                    # sample) and the high variability of the observations
                    # (standard deviation = 1.6)
 
 # Now, what does a t-test do? It tries to draw the same kind of inference
 # without having to get the distribution of the test statistic (the difference
 # in the sample means) by doing simulation.
                    
?ttest
help.search("ttest")

?t.test
 
t.test(xdata.orig,ydata.orig,var.equal=T)
# in the next 4 lines we increase the difference between the means. At some
# point the sample means are so different that we have to conclude the
# population means are different

t.test(xdata.orig+.2,ydata.orig,var.equal=T)
t.test(xdata.orig+.4,ydata.orig,var.equal=T)
t.test(xdata.orig+.6,ydata.orig,var.equal=T)
t.test(xdata.orig+.8,ydata.orig,var.equal=T)

# note that as the sample means get further apart, the probability of observing
# this difference becomes smaller and smaller under the null hypothesis 
# (that the means are the same)

# now let's look at a paired t-test

t.test(xdata.orig,ydata.orig,var.equal=T,paired=T)
# Note the degrees of freedom compared to the unpaired test.

# Are degrees of freedom good?

cor(xdata,ydata)     # x & y happen to have a modest correlation

# one sample t.test:  is the mean of xdata different from 0?

t.test(xdata)

