# MS698 - Statistical and Graphical Analysis in R                     Fall, 2010 

# Instructor:	Janos (John) M. Hoenig 
# Contact:	hoenig@vims.edu  
#           office: x7125; home: 757 564 9766; cell: 804 815 2912


# nonlinear regression: fitting a von Bertalanffy growth curve using nls()
#
# the data are 15 observations of age, length for butterflyfish. The ages were
# determined by counting daily growth rings in the otoliths.

# The data are in the file butterflyfish_growth.txt and there are two lines of
# header followed by one line of column headings (variable names) and 15 rows
# of data

butter = read.table("butterflyfish_growth.txt",skip=2,header=T)
butter

# let's plot the data
plot(butter$ages,butter$lengths)

# let's start the x-axis at 0 and the y-axis at 0. Also, let's join the data
# points

plot(butter$ages,butter$lengths,xlim=c(0,400),ylim=c(0,90),typ="b")
#  OOOOPS! the data are not sorted so the lines don't make much sense. Let's
# quickly sort the data.

sorted.butter = butter[order(butter$ages),]
sorted.butter
# what this did was give us a "subset" of butter where the rows we wanted
# were specified to the left of the comma and the columns we wanted were
# specifed to the right of the comma. Because we put nothing to the right of the
# comma it gave us all columns. What we put to the left of the comma was a set
# of row numbers we wanted and it gave us the rows in the order that we
# specified (which was such that we got sorted ages). See the script called
# sorting.r in the folder called "sorting, rev, order, rank, merging" for more
# information on order()

plot(sorted.butter$ages,sorted.butter$lengths,xlim=c(0,400),ylim=c(0,90),typ="b")

# OK, it was important to plot the data to make sure the curve is "bending over"
# If the curve looked straight or curving upward we wouldn't be able to fit
# the asymptotic (bending over) von Bertalanffy growth curve.

# Now let's fit the von Bertalanffy curve: length = Linf*(1-exp(-k*(age-to)))

# we'll use the nls( ) function in R (which stands for nonlinear least squares)

? nls
# we see that nls wants a formula, the name of the dataframe containing the
# variables, and a list with the starting values

growth.curve = nls(lengths~Linf*(1-exp(-k*(ages-to))),data=butter,
 start=list(Linf=90,k=.001,to=-30))
# list() creates a list, in this case with 3 "things" (components): Linf, which
# is a scalar with the value 90; k, another scalar with the value .001; and to,
# another scalar with the value -30.

growth.curve
summary(growth.curve)   # note that the parameter estimates are not very
                        # precise (large standard errors relative to the
                        # size of the parameter estimates

for.plotting=predict(growth.curve)  # get a predicted length for each age
for.plotting

par(new=T)    # this means "add the following to the existing plot"
plot(butter$ages,for.plotting,xlim=c(0,400),ylim=c(0,90),typ="l",lty=2,
   xlab="",ylab="")

# OOOOPS again. I used the unsorted data. (Look above where I did the
# regression. You'll see I specified the data is butter.)

# Let's try again. I'll use the sorted data

growth.curve = nls(lengths~Linf*(1-exp(-k*(ages-to))),data=sorted.butter,
 start=list(Linf=90,k=.001,to=-30))

plot(sorted.butter$ages,sorted.butter$lengths,xlim=c(0,400),ylim=c(0,90),typ="b")

for.plotting=predict(growth.curve)  # get a predicted length for each age
for.plotting

par(new=T)    # this means "add the following to the existing plot"
plot(sorted.butter$ages,for.plotting,xlim=c(0,400),ylim=c(0,90),typ="l",lty=2,
   xlab="",ylab="")
   
# Note that in R there are many ways to do things. Here are two variations
# on the theme.

# First, in nls() you don't have to specify data= if you specify the full names
# of the variables. Thus, the two statements which follow are equivalent:

growth.curve = nls(lengths~Linf*(1-exp(-k*(ages-to))),data=sorted.butter,
 start=list(Linf=90,k=.001,to=-30))
 
growth.curve = nls(sorted.butter$lengths~Linf*(1-exp(-k*(sorted.butter$ages-to))),
 start=list(Linf=90,k=.001,to=-30))

# second, we can avoid sorting the data and still get points to plot by telling
# predict() the values of the x-variable for which we want predictions.

?predict   # Note: this indicates that you can make predictions for the values
           # specified by newdata
for.plotting=predict(growth.curve,newdata=c(100,200,300,400))
for.plotting
# Hmmmmmm, there is something very strange here. We asked for predictions for
# just 4 values of age and it gave us 15 predictions (one for each data point
# we have).

# The mystery is solved by looking further down the help page where it says
# "See Also". If we click on predict.nls we get to the help page for this
# "method". There, under arguments, it says that newdata must be a named list.

for.plotting=predict(growth.curve,newdata=list(ages=c(100,200,300,400)))
# Note: it said we needed a "named list", and when we invoked the function
# list we named the vector of four numbers with the name "ages"
 
for.plotting

# OK, so what happened? in the predict() function we told R to use the
# growth parameter estimates in growth.curve to compute predictions. The
# default is to compute predictions for each value of x (in this case ages) in
# the dataset. But, we wanted to compute predictions just for 100, 200, 300 and
# 400. So, we had to tell R we want new data, and where ages was used before we
# want to substitute the new values 100, 200, etc.

# (This is another example of where it helps to have someone show you the trick.
# Otherwise, you would have to be energetic enough to follow a trail through the
# help pages to find the explanation for newdata.)

# There is one more trick. If you try to specify newdata= in a call to the
# predict() function you may get an error message if you specify the variable
# to be replaced (with new data) using the $ notation. For example,
# newdata=list(butter$ages= ... may give you a hard time. The solution is to
# extract the variables from the dataframe and give them new names so you can
# refer to the x-variable by name and not as a column of a dataframe.

# OK, after all that, it turns out there's an even easier way to get values to
# plot: use curve()
Linf=coef(growth.curve)[1]   # coef() extracts the parameter estimates 
k = coef(growth.curve)[2]
to = coef(growth.curve)[3]
curve(Linf*(1-exp(-k*(x-to))),0,400,add=T,col=2)  # compute points for plotting
                                                  # for x-variable ranging from
                                                  # 0 to 400 and add curve to
                                                  # existing plot

# let's focus on the parameter estimates
summary(growth.curve)
# we have the standard errors of the parameter estimates. But how about
# confidence intervals

confint(growth.curve)   # For this example, the profile confidence intervals
                        # can't be computed, presumably because the data
                        # are inadequate

################################################################################
# Let's try another example: a length-weight regression
#
# we'll fit a curve of the form weight = a * length^b .
# Usually b has a value around 3 so we can use that as a starting guess.

lenwt = read.table("Leiognathus_length_wt_data.txt",header=T)
lenwt
# let's give our variables simpler names
lengths = lenwt$lengths
mean.wt = lenwt$mean.wt
sampsize = lenwt$n

plot(lengths,mean.wt)     # look at the data
plot(lengths,mean.wt,xlim=c(0,15),ylim=c(0,70))   # better axes

# use nls() to do the regression. We specify the formula, the starting guesses,
# and in this case we'll weight by the sample sizes because for some lengths
# there's only a single weight recorded but for other lengths there are more
# than 20 weight observations. (Don't get confused by the two uses of the
# word weight. Weight refers to a measurement on a fish (number of grams). But,
# in statistics, weight refers to how much influence a datapoint should have.
# Data points that are means of observations should have their influence
# determined by how many observations were made to get the average.)

len.wt.reg = nls(mean.wt~a*lengths^b,start=list(a=1,b=3),weights=sampsize)
summary(len.wt.reg)  # Note that R tells you it deleted 2 observations because
                     # of missing values

# let's plot the regression line. For this, we need predicted weights for each
# length. We get the predictions from predict()
for.plotting = predict(len.wt.reg)
par(new=T)
plot(lengths,for.plotting,xlim=c(0,15),ylim=c(0,70),typ="l")

# Ooooops. why are the x-data and the y-data of different lengths?
length(for.plotting)   # 17 values
length(lengths)        # 19 values
# Ah, predict() did not give us predictions for the 2 lengths for which the
# weight data were missing

# we need to subset lengths to get rid of 2 values
plotting.lengths = lengths[!is.na(mean.wt)]
# note what the line above is doing. is.na(mean.wt) gives you a vector of
# TRUE and FALSE values according to whether the mean weight is missing or not.
is.na(mean.wt)
# The symbol ! means "not", so now we're asking if the mean weight
# is not missing
!is.na(mean.wt)
# finally, the square brackets [ ]  means give me all the lengths for which
# the corresponding mean weight is not missing.
plotting.lengths
length(plotting.lengths)

plot(plotting.lengths,for.plotting,xlim=c(0,15),ylim=c(0,70),typ="l",xlab="",
   ylab="")

# Again, it would have been easier to use curve() to add the fitted line to the
# graph
a = coef(len.wt.reg)[1]
b = coef(len.wt.reg)[2]
a
b
curve(a*x^b,0,15,add=T,col=2)
##################
# let's try to get the confidence intervals for the parameter estimates
confint(len.wt.reg)
##################

##### Handy reference:
# The following functions are "generic" which means they will recognize the
# "class" of the object being passed in (modelname) and use the appropriate
# "method" to compute the results. Thus, they can be used with output from
# lm(), glm(), nls() and other functions

# plot(modelname)        produces diagnostic plots like residuals, influence,...
# residuals(modelname)   observed values minus predicted values
# fitted(modelname)      fitted or predicted value for each complete observation
# predict(modelname)     fitted or predicted value for each complete observation
#                           or for specified values of the x-variables
#
# in addition, the following functions are available, though they don't
# pertain to the subject of this script, i.e., graphing results
# coef(modelname)         extract the parameter estimates
# confint(modelname)      compute confidence intervals for the parameter estim.
# anova(modelname)        anova table for a model, or for comparing multiple
#                            models fitted to the same data
# summary(modelname)      your basic regression results
# influence.measures()    influence of each datapoint on the regression estim.
# poly()                  fit model with a polynomial function of x
# add1()                  find the single variable that best improves the fit
# drop1()                 find the least important variable and drop it from fit
# step()                  stepwise regression
